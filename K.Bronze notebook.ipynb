{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e414536-8c5d-4235-be63-fc4b9972cad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# required each time the cluster is restarted which should be only on the first notebook as they run in order \n",
    "\n",
    "\n",
    "tiers = ['bronze','silver','gold']\n",
    "adls_path = {tiers:f\"abfss://{tiers}@dbprojectearthquack.dfs.core.windows.net/\" for tiers in tiers}\n",
    "\n",
    "\n",
    "#Accessing paths \n",
    "\n",
    "bronze_adls = adls_path['bronze']\n",
    "silver_adls = adls_path['silver']\n",
    "gold_adls = adls_path['gold']\n",
    "\n",
    "dbutils.fs.ls(bronze_adls)\n",
    "dbutils.fs.ls(silver_adls)\n",
    "dbutils.fs.ls(gold_adls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63274f11-40b5-43aa-b9eb-d28f7ada947c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "What the code is doing in simple terms\n",
    "\n",
    "You have three storage areas called Bronze, Silver, and Gold.\n",
    "\n",
    "Think of them like three different folders in a big online storage drive.\n",
    "\n",
    "Bronze might hold raw, unprocessed data.\n",
    "\n",
    "Silver might hold cleaned and organized data.\n",
    "\n",
    "Gold might hold final, ready-to-use data.\n",
    "\n",
    "You’re creating a map (dictionary) that links each storage area’s name to its web address (path) in Azure Data Lake Storage (ADLS).\n",
    "\n",
    "The code automatically builds these paths using the names \"bronze\", \"silver\", and \"gold\".\n",
    "\n",
    "Example: \"bronze\" gets linked to something like abfss://bronze@dbprojectearthquack.dfs.core.windows.net/.\n",
    "\n",
    "You save each path into a variable so you can easily refer to it later.\n",
    "\n",
    "bronze_adls = web address for Bronze folder.\n",
    "\n",
    "silver_adls = web address for Silver folder.\n",
    "\n",
    "gold_adls = web address for Gold folder.\n",
    "\n",
    "You check what’s inside each folder using dbutils.fs.ls() —\n",
    "\n",
    "This command is like opening the folder in File Explorer or Google Drive to see what files are inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f65fbf1b-c21b-488f-bf89-76df93be0329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "811a7141-c482-4e75-9372-48855ffcba96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start_date = date.today() - timedelta(1)\n",
    "end_date = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a9d66df-9d85-448d-97e5-6e2bcfb0967e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "requests\n",
    "\n",
    "A popular Python library used to send HTTP requests (like visiting websites, downloading data, or talking to APIs).\n",
    "\n",
    "Example: If you want to get weather data from a web service, requests is the tool that makes the call and gets the response.\n",
    "\n",
    "json\n",
    "\n",
    "A built-in Python library for working with JSON data (JavaScript Object Notation).\n",
    "\n",
    "JSON is a way to store and send structured data — looks like a dictionary but in text form.\n",
    "\n",
    "You use json to convert data between Python objects and JSON text.\n",
    "\n",
    "from datetime import date, timedelta\n",
    "\n",
    "You’re importing date (to work with calendar dates like today’s date).\n",
    "\n",
    "And timedelta (to represent a difference in time — for example, \"5 days ago\" or \"next 7 days\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b32b9e77-6034-471f-916e-17377e8282e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 303549 bytes.\nSaved 244 records to abfss://bronze@dbprojectearthquack.dfs.core.windows.net//2025-09-16_earthquake_data.json\n"
     ]
    }
   ],
   "source": [
    "# API URL\n",
    "url = f\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime={start_date}&endtime={end_date}\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make the GET request to fetch data\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    response.raise_for_status() # Raise an exception if the request was unsuccessful\n",
    "\n",
    "    try:\n",
    "        data = response.json().get(\"features\", [])\n",
    "        if not data:\n",
    "            print(\"No earthquake data found.\")\n",
    "        else:\n",
    "            json_data = json.dumps(data, indent=4)\n",
    "            file_path = f\"{bronze_adls}/{start_date}_earthquake_data.json\"\n",
    "            dbutils.fs.put(file_path, json_data, overwrite=True)\n",
    "            print(f\"Saved {len(data)} records to {file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON\")\n",
    "        print(\"Response:\\n\", response.text[:500])\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35078392-634c-4711-8173-c6dbe38df932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'properties': {'mag': 4.4,\n",
       "  'place': '33 km NNE of Mejillones, Chile',\n",
       "  'time': 1758066789194,\n",
       "  'updated': 1758068087040,\n",
       "  'tz': None,\n",
       "  'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us7000qwky',\n",
       "  'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us7000qwky&format=geojson',\n",
       "  'felt': None,\n",
       "  'cdi': None,\n",
       "  'mmi': None,\n",
       "  'alert': None,\n",
       "  'status': 'reviewed',\n",
       "  'tsunami': 0,\n",
       "  'sig': 298,\n",
       "  'net': 'us',\n",
       "  'code': '7000qwky',\n",
       "  'ids': ',us7000qwky,',\n",
       "  'sources': ',us,',\n",
       "  'types': ',origin,phase-data,',\n",
       "  'nst': 19,\n",
       "  'dmin': 0.739,\n",
       "  'rms': 0.32,\n",
       "  'gap': 153,\n",
       "  'magType': 'mb',\n",
       "  'type': 'earthquake',\n",
       "  'title': 'M 4.4 - 33 km NNE of Mejillones, Chile'},\n",
       " 'geometry': {'type': 'Point', 'coordinates': [-70.3643, -22.8115, 35]},\n",
       " 'id': 'us7000qwky'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8211110-a371-42dc-9919-f82e3b97ec56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "What this code does\n",
    "\n",
    "It connects to the US Geological Survey (USGS) earthquake API to get earthquake data for yesterday up to today, and then stores it in your Bronze layer in Azure Data Lake.\n",
    "\n",
    "Step-by-step breakdown\n",
    "\n",
    "Build the API link\n",
    "\n",
    "url = f\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime={start_date}&endtime={end_date}\"\n",
    "\n",
    "\n",
    "This creates a website link (API URL) that says:\n",
    "\n",
    "“Give me earthquake data in GeoJSON format from {start_date} to {end_date}.”\n",
    "\n",
    "start_date = yesterday, end_date = today.\n",
    "\n",
    "Set request headers\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "\n",
    "Pretends you’re a normal web browser so the server doesn’t block you.\n",
    "\n",
    "Make the request to get earthquake data\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "This sends the request to the API and waits for the earthquake data.\n",
    "\n",
    "Check if the request worked\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "\n",
    "If something went wrong (like wrong link, server down, or no internet), this will throw an error.\n",
    "\n",
    "Process the data\n",
    "\n",
    "data = response.json().get(\"features\", [])\n",
    "\n",
    "\n",
    "Reads the API’s JSON response and takes the \"features\" section (which contains the earthquake records).\n",
    "\n",
    "If there’s no \"features\" key, it just gives an empty list.\n",
    "\n",
    "If no data, show message\n",
    "\n",
    "if not data:\n",
    "    print(\"No earthquake data found.\")\n",
    "\n",
    "\n",
    "Lets you know if there were no earthquakes in that date range.\n",
    "\n",
    "If there’s data, save it to the Bronze layer\n",
    "\n",
    "json_data = json.dumps(data, indent=4)\n",
    "file_path = f\"{bronze_adls}/{start_date}_earthquake_data.json\"\n",
    "dbutils.fs.put(file_path, json_data, overwrite=True)\n",
    "\n",
    "\n",
    "Converts the earthquake data into nicely formatted JSON text.\n",
    "\n",
    "Creates a file name like:\n",
    "\n",
    "bronze_layer/2025-08-13_earthquake_data.json\n",
    "\n",
    "\n",
    "Saves the file in your Bronze area in ADLS.\n",
    "\n",
    "If JSON parsing fails\n",
    "\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse JSON\")\n",
    "\n",
    "\n",
    "If the data from the API isn’t in valid JSON format, it shows an error.\n",
    "\n",
    "If network request fails\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "\n",
    "\n",
    "Shows an error if the request couldn’t even reach the API.\n",
    "\n",
    "Plain-English Summary\n",
    "\n",
    "This script:\n",
    "\n",
    "Figures out yesterday and today’s dates.\n",
    "\n",
    "Asks the official US earthquake service for earthquake events between those dates.\n",
    "\n",
    "If found, it saves them into your Bronze storage layer in Azure Data Lake as a JSON file.\n",
    "\n",
    "If no quakes or an error happens, it prints a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7af94c76-adea-490e-8594-b4eea8392d86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze task values stored: {'start_date': '2025-09-16', 'end_date': '2025-09-17', 'bronze_adls': 'abfss://bronze@dbprojectearthquack.dfs.core.windows.net/', 'silver_adls': 'abfss://silver@dbprojectearthquack.dfs.core.windows.net/', 'gold_adls': 'abfss://gold@dbprojectearthquack.dfs.core.windows.net/'}\n"
     ]
    }
   ],
   "source": [
    "# define your variables \n",
    "\n",
    "output_data = {\n",
    "\n",
    "    \"start_date\":start_date.isoformat(),\n",
    "    \"end_date\":end_date.isoformat(),\n",
    "    \"bronze_adls\": bronze_adls,\n",
    "    \"silver_adls\": silver_adls,\n",
    "    \"gold_adls\": gold_adls\n",
    "}\n",
    "\n",
    "# return the dictonery directly \n",
    "\n",
    "dbutils.jobs.taskValues.set(key=\"bronze_output\", value= output_data)\n",
    "\n",
    "print(\"Bronze task values stored:\", output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "582483f0-7c06-43d2-b925-b756d706e41e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create a dictionary of important information\n",
    "\n",
    "output_data = {\n",
    "    \"start_date\": start_date.isoformat(),\n",
    "    \"end_date\": end_date.isoformat(),\n",
    "    \"bronze_adls\": bronze_adls,\n",
    "    \"silver_adls\": silver_adls,\n",
    "    \"gold_adls\": gold_adls\n",
    "}\n",
    "\n",
    "\n",
    "This builds a small package of variables (like putting them all in a labeled box).\n",
    "\n",
    "start_date.isoformat() → turns the date into a text string like \"2025-08-13\".\n",
    "\n",
    "Same for end_date.\n",
    "\n",
    "It also stores the paths for Bronze, Silver, and Gold ADLS folders.\n",
    "\n",
    "Share the dictionary with another Databricks task\n",
    "\n",
    "dbutils.jobs.taskValues.set(key=\"bronze_output\", value=output_data)\n",
    "\n",
    "\n",
    "This saves the whole dictionary into Databricks job task values under the name \"bronze_output\".\n",
    "\n",
    "Think of it like handing off these values so another task later in the same job can use them.\n",
    "\n",
    "This is especially useful if:\n",
    "\n",
    "Task 1 gets the data\n",
    "\n",
    "Task 2 processes it\n",
    "\n",
    "Task 3 moves it to another location\n",
    "\n",
    "Plain-English Summary\n",
    "\n",
    "You’re basically saying:\n",
    "\n",
    "“Here are my start and end dates, and my storage folder paths. I’m packaging them up and passing them to the next task in this Databricks job so it can use them without recalculating everything.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c170481-3e63-4b66-83b0-4d26f8e23956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "K.Bronze notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}